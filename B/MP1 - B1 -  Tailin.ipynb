{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "i: 1000\n",
      "i: 2000\n",
      "i: 3000\n",
      "i: 4000\n",
      "i: 5000\n",
      "i: 6000\n",
      "i: 7000\n",
      "i: 8000\n",
      "i: 9000\n",
      "i: 10000\n",
      "i: 11000\n",
      "i: 12000\n",
      "i: 13000\n",
      "i: 14000\n",
      "i: 15000\n",
      "i: 16000\n",
      "i: 17000\n",
      "i: 18000\n",
      "i: 19000\n",
      "i: 20000\n",
      "i: 21000\n",
      "i: 22000\n",
      "i: 23000\n",
      "i: 24000\n",
      "i: 25000\n",
      "i: 26000\n",
      "i: 27000\n",
      "i: 28000\n",
      "i: 29000\n",
      "i: 30000\n",
      "i: 31000\n",
      "i: 32000\n",
      "i: 33000\n",
      "i: 34000\n",
      "i: 35000\n",
      "i: 36000\n",
      "i: 37000\n",
      "i: 38000\n",
      "i: 39000\n",
      "i: 40000\n",
      "i: 41000\n",
      "i: 42000\n",
      "i: 43000\n",
      "i: 44000\n",
      "i: 45000\n",
      "i: 46000\n",
      "i: 47000\n",
      "i: 48000\n",
      "i: 49000\n",
      "i: 50000\n",
      "i: 51000\n",
      "i: 52000\n",
      "i: 53000\n",
      "i: 54000\n",
      "i: 55000\n",
      "i: 56000\n",
      "i: 57000\n",
      "i: 58000\n",
      "i: 59000\n",
      "i: 0\n",
      "i: 1000\n",
      "i: 2000\n",
      "i: 3000\n",
      "i: 4000\n",
      "i: 5000\n",
      "i: 6000\n",
      "i: 7000\n",
      "i: 8000\n",
      "i: 9000\n"
     ]
    }
   ],
   "source": [
    "# Author : Martin Thoma \n",
    "# URL : https://martin-thoma.com/classify-mnist-with-pybrain/\n",
    "\n",
    "from struct import unpack\n",
    "import gzip\n",
    "import numpy as np\n",
    "from numpy import zeros, uint8, float32\n",
    "\n",
    "def get_labeled_data(imagefile, labelfile):\n",
    "    \"\"\"Read input-vector (image) and target class (label, 0-9) and return\n",
    "       it as list of tuples.\n",
    "    \"\"\"\n",
    "    # Open the images with gzip in read binary mode\n",
    "    images = gzip.open(imagefile, 'rb')\n",
    "    labels = gzip.open(labelfile, 'rb')\n",
    "\n",
    "    # Read the binary data\n",
    "\n",
    "    # We have to get big endian unsigned int. So we need '>I'\n",
    "\n",
    "    # Get metadata for images\n",
    "    images.read(4)  # skip the magic_number\n",
    "    number_of_images = images.read(4)\n",
    "    number_of_images = unpack('>I', number_of_images)[0]\n",
    "    rows = images.read(4)\n",
    "    rows = unpack('>I', rows)[0]\n",
    "    cols = images.read(4)\n",
    "    cols = unpack('>I', cols)[0]\n",
    "\n",
    "    # Get metadata for labels\n",
    "    labels.read(4)  # skip the magic_number\n",
    "    N = labels.read(4)\n",
    "    N = unpack('>I', N)[0]\n",
    "\n",
    "    if number_of_images != N:\n",
    "        raise Exception('number of labels did not match the number of images')\n",
    "\n",
    "    # Get the data\n",
    "    x = zeros((N, rows, cols), dtype=float32)  # Initialize numpy array\n",
    "    y = zeros((N, 1), dtype=uint8)  # Initialize numpy array\n",
    "    for i in range(N):\n",
    "        if i % 1000 == 0:\n",
    "            print(\"i: %i\" % i)\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                tmp_pixel = images.read(1)  # Just a single byte\n",
    "                tmp_pixel = unpack('>B', tmp_pixel)[0]\n",
    "                x[i][row][col] = tmp_pixel\n",
    "        tmp_label = labels.read(1)\n",
    "        y[i] = unpack('>B', tmp_label)[0]\n",
    "    return (x, y)\n",
    "\n",
    "x_train, y_train = get_labeled_data(\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\")\n",
    "x_test, y_test = get_labeled_data(\"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_x_train = threshold(x_train)\n",
      "t_x_test = threshold(x_test)\n",
      "rt_x_train = threshold(resize(x_train))\n",
      "rt_x_test = threshold(resize(x_test))\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import cv2\n",
    "from pylab import imshow, show, cm\n",
    "\n",
    "\n",
    "def view_image(image, label=\"\"):\n",
    "    \"\"\"View a single image.\"\"\"\n",
    "    print(\"Label: %s\" % label)\n",
    "    imshow(image, cmap=cm.gray)\n",
    "    show()\n",
    "\n",
    "    \n",
    "def threshold(s):\n",
    "    size = len(s[0])\n",
    "    ret = copy.deepcopy(s)\n",
    "    for i in ret:\n",
    "        for j in range(0, size):\n",
    "            for k in range(0, size):\n",
    "                if i[j][k]<128:\n",
    "                    i[j][k] = 0\n",
    "                else:\n",
    "                    i[j][k] = 1\n",
    "    return ret\n",
    "\n",
    "\n",
    "def resize(images):\n",
    "    size = len(images[0])\n",
    "    image_list = []\n",
    "    for image in images:\n",
    "        f_break = False\n",
    "        for x in range(0, size):\n",
    "            for y in range(0, size):\n",
    "                if image[y][x]!=0.0:\n",
    "                    x_min = x   \n",
    "                    f_break = True\n",
    "                    break\n",
    "            if f_break:\n",
    "                break\n",
    "\n",
    "        f_break = False\n",
    "        for x in range(size-1,-1,-1):\n",
    "            for y in range(0, size):\n",
    "                if image[y][x]!=0.0:\n",
    "                    x_max = x   \n",
    "                    f_break = True\n",
    "                    break\n",
    "            if f_break:\n",
    "                break\n",
    "\n",
    "        f_break = False\n",
    "        for y in range(0, size):\n",
    "            for x in range(0, size):\n",
    "                if image[y][x]!=0.0:\n",
    "                    y_min = y    \n",
    "                    f_break = True\n",
    "                    break\n",
    "            if f_break:\n",
    "                break\n",
    "\n",
    "        f_break = False\n",
    "        for y in range(size-1,-1,-1):\n",
    "            for x in range(0, size):\n",
    "                if image[y][x]!=0.0:\n",
    "                    y_max = y    \n",
    "                    f_break = True\n",
    "                    break\n",
    "            if f_break:\n",
    "                break\n",
    "\n",
    "        temp_image = image[y_min: y_max+1]\n",
    "        new_image = temp_image[..., x_min: x_max+1]\n",
    "        final_image = cv2.resize(np.asarray(new_image),(20,20))\n",
    "#         view_image(final_image)\n",
    "        image_list.append(final_image)\n",
    "    return np.asarray(image_list)\n",
    "\n",
    "print(\"t_x_train = threshold(x_train)\")\n",
    "t_x_train = threshold(x_train)\n",
    "print(\"t_x_test = threshold(x_test)\")\n",
    "t_x_test = threshold(x_test)\n",
    "print(\"rt_x_train = threshold(resize(x_train))\")\n",
    "rt_x_train = threshold(resize(x_train))\n",
    "print(\"rt_x_test = threshold(resize(x_test))\")\n",
    "rt_x_test = threshold(resize(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Naive Bayes Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def naiveBayesG(train_set, train_labels, test_set, test_labels):\n",
    "    # return predicted labels of test set\n",
    "    \n",
    "    print(\"calculaing...\")\n",
    "    size = len(train_set[0])\n",
    "    # index corresponding to each label \n",
    "    dict_train_index = {}\n",
    "    # probability corresponding to each label\n",
    "    probability = {}\n",
    "    for i in range(0, 10):\n",
    "        dict_train_index[i] = list(np.where(np.asarray(train_labels) == i)[0])\n",
    "        probability[i] = len(dict_train_index[i])/len(train_labels)\n",
    "        \n",
    "#     dataset corresponding to each label\n",
    "    dict_train_set = {}\n",
    "    for i in range(0, 10):\n",
    "        dict_train_set[i] = np.asarray([train_set[j] for j in dict_train_index[i]])  \n",
    "    \n",
    "#     mean and var for images' features\n",
    "    mean_list = np.empty([10,size,size])\n",
    "    var_list = np.empty([10,size,size])\n",
    "    for i in range(0, 10):  \n",
    "        for j in range(0, size):\n",
    "            for k in range(0, size):\n",
    "                feature_list = []\n",
    "                for m in range(0, len(dict_train_set[i])):\n",
    "                    feature_list.append(dict_train_set[i][m][j][k])\n",
    "                feature_mean = np.mean(feature_list)\n",
    "                mean_list[i][j][k] = feature_mean\n",
    "                feature_var = np.var(feature_list)\n",
    "                var_list[i][j][k] = feature_var\n",
    "                \n",
    "# #    view mean image\n",
    "#     for i in range(0, 10):\n",
    "#         view_image(mean_list[i], i)\n",
    "      \n",
    " # compare the probability of test set for each label   \n",
    "    print(\"comparing...\")\n",
    "    label = []\n",
    "    count = 0\n",
    "    for s in test_set:\n",
    "        count += 1\n",
    "        if count%500 == 0:\n",
    "            print(count)\n",
    "        dict_compare = {}\n",
    "        for i in range(0, 10):\n",
    "            dict_compare[i] = np.log(probability[i])\n",
    "            for j in range(0, size):\n",
    "                for k in range(0, size):\n",
    "                    if var_list[i][j][k] != 0:\n",
    "                        p = norm.pdf(s[j][k], mean_list[i][j][k], np.sqrt(var_list[i][j][k]))\n",
    "                        if p == 0:\n",
    "                            p = 1e-15\n",
    "                        dict_compare[i] += np.log(p)\n",
    "        label.append(max(dict_compare, key=dict_compare.get))\n",
    "        \n",
    "# compute accuracy\n",
    "    print(\"computing accuracy...\")\n",
    "    correct = 0\n",
    "    for i in range(0, len(test_labels)):\n",
    "        if test_labels[i][0] == label[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct/len(test_labels)\n",
    "    print(\"Guassian NB accuarcy: \", accuracy)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def naiveBayesB(train_set, train_labels, test_set, test_labels):\n",
    "    # return predicted labels of test set\n",
    "    \n",
    "    print(\"calculaing...\")\n",
    "    size = len(train_set[0])\n",
    "    # index corresponding to each label \n",
    "    dict_train_index = {}\n",
    "    # probability corresponding to each label\n",
    "    probability = {}\n",
    "    for i in range(0, 10):\n",
    "        dict_train_index[i] = list(np.where(np.asarray(train_labels) == i)[0])\n",
    "        probability[i] = len(dict_train_index[i])/len(train_labels)\n",
    "        \n",
    "#     dataset corresponding to each label\n",
    "    dict_train_set = {}\n",
    "    for i in range(0, 10):\n",
    "        dict_train_set[i] = np.asarray([train_set[j] for j in dict_train_index[i]])  \n",
    "    \n",
    "#     p for images' features\n",
    "    p_zero_list = np.empty([10,size,size])\n",
    "    p_one_list = np.empty([10,size,size])\n",
    "    for i in range(0, 10):  \n",
    "        for j in range(0, size):\n",
    "            for k in range(0, size):\n",
    "                feature_list = []\n",
    "                for m in range(0, len(dict_train_set[i])):\n",
    "                    feature_list.append(dict_train_set[i][m][j][k])  \n",
    "                p_zero = feature_list.count(0)/len(feature_list)\n",
    "                p_zero_list[i][j][k] = p_zero\n",
    "                p_one_list[i][j][k] = 1-p_zero\n",
    "                \n",
    "# #    view mean image\n",
    "#     for i in range(0, 10):\n",
    "#         view_image(mean_list[i], i)\n",
    "      \n",
    " # compare the probability of test set for each label   \n",
    "    print(\"comparing...\")\n",
    "    label = []\n",
    "    count = 0\n",
    "    for s in test_set:\n",
    "        count += 1\n",
    "        if count%500 == 0:\n",
    "            print(count)\n",
    "        dict_compare = {}\n",
    "        for i in range(0, 10):\n",
    "            dict_compare[i] = np.log(probability[i])\n",
    "            for j in range(0, size):\n",
    "                for k in range(0, size):\n",
    "                    if s[j][k] == 0:\n",
    "                        p = p_zero_list[i][j][k]\n",
    "                    else:\n",
    "                        p = p_one_list[i][j][k]\n",
    "                    if p == 0:\n",
    "                        p = 1e-15\n",
    "                    dict_compare[i] += np.log(p)\n",
    "        label.append(max(dict_compare, key=dict_compare.get))\n",
    "        \n",
    "# compute accuracy\n",
    "    print(\"computing accuracy...\")\n",
    "    correct = 0\n",
    "    for i in range(0, len(test_labels)):\n",
    "        if test_labels[i][0] == label[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct/len(test_labels)\n",
    "    print(\"Bernouilli NB accuarcy: \", accuracy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untouched Guassian: \n",
      "calculaing...\n",
      "comparing...\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "computing accuracy...\n",
      "Guassian NB accuarcy:  0.7805\n",
      "Resized Guassian: \n",
      "calculaing...\n",
      "comparing...\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "computing accuracy...\n",
      "Guassian NB accuarcy:  0.8207\n",
      "Untouched Bernouilli: \n",
      "calculaing...\n",
      "comparing...\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "computing accuracy...\n",
      "Bernouilli NB accuarcy:  0.8439\n",
      "Resized Bernouilli: \n",
      "calculaing...\n",
      "comparing...\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "computing accuracy...\n",
      "Bernouilli NB accuarcy:  0.8273\n"
     ]
    }
   ],
   "source": [
    "print(\"Untouched Guassian: \")\n",
    "naiveBayesG(t_x_train, y_train, t_x_test, y_test)\n",
    "print(\"Resized Guassian: \")\n",
    "naiveBayesG(rt_x_train, y_train, rt_x_test, y_test)\n",
    "\n",
    "print(\"Untouched Bernouilli: \")\n",
    "naiveBayesB(t_x_train, y_train, t_x_test, y_test)\n",
    "print(\"Resized Bernouilli: \")\n",
    "naiveBayesB(rt_x_train, y_train, rt_x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result:\n",
    "Untouched Guassian NB accuarcy:  0.7805\n",
    "Resized Guassian NB accuarcy:  0.8207\n",
    "Untouched Bernouilli NB accuarcy:  0.8439\n",
    "Resized Bernouilli NB accuarcy:  0.8273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
