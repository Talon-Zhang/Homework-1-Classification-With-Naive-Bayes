{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "i: 1000\n",
      "i: 2000\n",
      "i: 3000\n",
      "i: 4000\n",
      "i: 5000\n",
      "i: 6000\n",
      "i: 7000\n",
      "i: 8000\n",
      "i: 9000\n",
      "i: 10000\n",
      "i: 11000\n",
      "i: 12000\n",
      "i: 13000\n",
      "i: 14000\n",
      "i: 15000\n",
      "i: 16000\n",
      "i: 17000\n",
      "i: 18000\n",
      "i: 19000\n",
      "i: 20000\n",
      "i: 21000\n",
      "i: 22000\n",
      "i: 23000\n",
      "i: 24000\n",
      "i: 25000\n",
      "i: 26000\n",
      "i: 27000\n",
      "i: 28000\n",
      "i: 29000\n",
      "i: 30000\n",
      "i: 31000\n",
      "i: 32000\n",
      "i: 33000\n",
      "i: 34000\n",
      "i: 35000\n",
      "i: 36000\n",
      "i: 37000\n",
      "i: 38000\n",
      "i: 39000\n",
      "i: 40000\n",
      "i: 41000\n",
      "i: 42000\n",
      "i: 43000\n",
      "i: 44000\n",
      "i: 45000\n",
      "i: 46000\n",
      "i: 47000\n",
      "i: 48000\n",
      "i: 49000\n",
      "i: 50000\n",
      "i: 51000\n",
      "i: 52000\n",
      "i: 53000\n",
      "i: 54000\n",
      "i: 55000\n",
      "i: 56000\n",
      "i: 57000\n",
      "i: 58000\n",
      "i: 59000\n",
      "i: 0\n",
      "i: 1000\n",
      "i: 2000\n",
      "i: 3000\n",
      "i: 4000\n",
      "i: 5000\n",
      "i: 6000\n",
      "i: 7000\n",
      "i: 8000\n",
      "i: 9000\n"
     ]
    }
   ],
   "source": [
    "# Author : Martin Thoma \n",
    "# URL : https://martin-thoma.com/classify-mnist-with-pybrain/\n",
    "\n",
    "from struct import unpack\n",
    "import gzip\n",
    "import numpy as np\n",
    "from numpy import zeros, uint8, float32\n",
    "\n",
    "def get_labeled_data(imagefile, labelfile):\n",
    "    \"\"\"Read input-vector (image) and target class (label, 0-9) and return\n",
    "       it as list of tuples.\n",
    "    \"\"\"\n",
    "    # Open the images with gzip in read binary mode\n",
    "    images = gzip.open(imagefile, 'rb')\n",
    "    labels = gzip.open(labelfile, 'rb')\n",
    "\n",
    "    # Read the binary data\n",
    "\n",
    "    # We have to get big endian unsigned int. So we need '>I'\n",
    "\n",
    "    # Get metadata for images\n",
    "    images.read(4)  # skip the magic_number\n",
    "    number_of_images = images.read(4)\n",
    "    number_of_images = unpack('>I', number_of_images)[0]\n",
    "    rows = images.read(4)\n",
    "    rows = unpack('>I', rows)[0]\n",
    "    cols = images.read(4)\n",
    "    cols = unpack('>I', cols)[0]\n",
    "\n",
    "    # Get metadata for labels\n",
    "    labels.read(4)  # skip the magic_number\n",
    "    N = labels.read(4)\n",
    "    N = unpack('>I', N)[0]\n",
    "\n",
    "    if number_of_images != N:\n",
    "        raise Exception('number of labels did not match the number of images')\n",
    "\n",
    "    # Get the data\n",
    "    x = zeros((N, rows, cols), dtype=float32)  # Initialize numpy array\n",
    "    y = zeros((N, 1), dtype=uint8)  # Initialize numpy array\n",
    "    for i in range(N):\n",
    "        if i % 1000 == 0:\n",
    "            print(\"i: %i\" % i)\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                tmp_pixel = images.read(1)  # Just a single byte\n",
    "                tmp_pixel = unpack('>B', tmp_pixel)[0]\n",
    "                x[i][row][col] = tmp_pixel\n",
    "        tmp_label = labels.read(1)\n",
    "        y[i] = unpack('>B', tmp_label)[0]\n",
    "    return (x, y)\n",
    "\n",
    "x_train, y_train = get_labeled_data(\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\")\n",
    "x_test, y_test = get_labeled_data(\"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import imshow, show, cm\n",
    "\n",
    "\n",
    "def view_image(image, label=\"\"):\n",
    "    \"\"\"View a single image.\"\"\"\n",
    "    print(\"Label: %s\" % label)\n",
    "    imshow(image, cmap=cm.gray)\n",
    "    show()\n",
    "    \n",
    "view_image(x_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def naiveBayes(train_set, train_labels, test_set):\n",
    "    # return predicted labels of test set\n",
    "\n",
    "    dict_train_label = {}\n",
    "    probability = {}\n",
    "    for i in range(0, 10):\n",
    "        dict_train_label[i] = list(np.where(np.asarray(train_labels) == i)[0])\n",
    "        probability[i] = len(dict_train_label[i])/60000\n",
    "\n",
    "    dict_train_set = {}\n",
    "    for i in range(0, 10):\n",
    "        dict_train_set = [train_set[j] for j in dict_train_label[i]]\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "#     # dictionary storing np.log(P(word|spam)). Key is the word in string\n",
    "#     spam_dict = {}\n",
    "#     # dictionary storing np.log(P(word|ham)). Key is the word in string\n",
    "#     ham_dict = {}\n",
    "\n",
    "#     # storing the (word count + smoothing_parameter) in the dict for each word\n",
    "#     for l in spam_list:\n",
    "#         for w in l:\n",
    "#             if w in spam_dict:\n",
    "#                 spam_dict[w] += 1\n",
    "#             else:\n",
    "#                 spam_dict[w] = 1+smoothing_parameter\n",
    "\n",
    "#     for l in ham_list:\n",
    "#         for w in l:\n",
    "#             if w in ham_dict:\n",
    "#                 ham_dict[w] += 1\n",
    "#             else:\n",
    "#                 ham_dict[w] = 1+smoothing_parameter\n",
    "\n",
    "#     # consider the laplace smoothing\n",
    "#     spam_dict['UNK'] = smoothing_parameter\n",
    "#     ham_dict['UNK'] = smoothing_parameter\n",
    "\n",
    "#     # now compute P(word|type) = \n",
    "#     # (word count + smoothing_parameter)/(tot # of words + smoothing_parameter*(# of different words + 1))\n",
    "#     # take the log and store in the dict\n",
    "#     denominator_spam = spam_word_count+smoothing_parameter*(len(spam_dict)+1)\n",
    "#     denominator_ham = ham_word_count+smoothing_parameter*(len(ham_dict)+1)\n",
    "\n",
    "#     for key in spam_dict.keys():\n",
    "#         n = spam_dict[key]\n",
    "#         spam_dict[key] = np.log(n/denominator_spam)\n",
    "#     for key in ham_dict.keys():\n",
    "#         n = ham_dict[key]\n",
    "#         ham_dict[key] = np.log(n/denominator_ham)\n",
    "\n",
    "#     # computing the probability for the dev_set. calculate both P(words|ham) and P(words|spam), and compare which\n",
    "#     # is larger\n",
    "#     dev_label = []\n",
    "#     for email in dev_set:\n",
    "#         P_spam = 0\n",
    "#         P_ham = 0\n",
    "#         for word in email:\n",
    "#             if word in spam_dict.keys():\n",
    "#                 P_spam += spam_dict[word]\n",
    "#             else:\n",
    "#                 P_spam += spam_dict['UNK']\n",
    "\n",
    "#             if word in ham_dict.keys():\n",
    "#                 P_ham += ham_dict[word]\n",
    "#             else:\n",
    "#                 P_ham += ham_dict['UNK']\n",
    "#         if P_spam > P_ham:\n",
    "#             dev_label.append(1)\n",
    "#         else:\n",
    "#             dev_label.append(0)\n",
    "\n",
    "#     return dev_label\n",
    "\n",
    "naiveBayes(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
